{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFbUpH8elWQ7"
   },
   "source": [
    "# **Part 1: Run MobileNet on GPU**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aoNr0MWd5e5m"
   },
   "source": [
    "In this tutorial, we will explore how to train a neural network with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoBtxdvR5lwM"
   },
   "source": [
    "### Setup (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0oLGv2RjLYh2"
   },
   "source": [
    "We will first install a few packages that will be used in this tutorial and also define the path of CUDA library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "3r7Sl2cG7nZF"
   },
   "outputs": [],
   "source": [
    "# !pip install torchprofile 1>/dev/null\n",
    "# !ldconfig /usr/lib64-nvidia 2>/dev/null\n",
    "# !pip install onnx 1>/dev/null\n",
    "# !pip install onnxruntime 1>/dev/null\n",
    "!export CUDA_VISIBLE_DEVICES=1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYgp0au_LeAd"
   },
   "source": [
    "We will then import a few libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "I3uAhaCSlFrK"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "D-nNU83gqm9U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "0.21.0+cu124\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1Yx0rDUK5fx"
   },
   "source": [
    "To ensure the reproducibility, we will control the seed of random generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "j_l1wEdeHOlu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe3a02fe530>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzMCWN0aJNvl"
   },
   "source": [
    "We must decide the HYPER-parameter before training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "AyLHUYWZJNCJ"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "# TODO:\n",
    "# Decide your own hyper-parameters\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_EPOCH = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7Y0sLyajGAu"
   },
   "source": [
    "### Data  (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAbL_li0KPsz"
   },
   "source": [
    "In this lab, we will use CIFAR-10 as our target dataset. This dataset contains images from 10 classes, where each image is of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PO2mP2GytNl"
   },
   "source": [
    "Before using the data as input, we can do data pre-processing with transform function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "Pqhy8EJSjJfp"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Resize images to 224x224, i.e., the input image size of MobileNet,\n",
    "# Convert images to PyTorch tensors, and\n",
    "# Normalize the images with mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CIFAR10(Dataset):\n",
    "  def __init__(self, root, train, transform, download):\n",
    "    self.root = root\n",
    "    self.train = train\n",
    "    self.transform = transform\n",
    "    self.download = download\n",
    "    self.data = None\n",
    "    self.labels = None\n",
    "    \n",
    "    if not os.path.exists(self.root):\n",
    "      os.makedirs(self.root)\n",
    "    \n",
    "    if self.download:\n",
    "      # download the cifar to root\n",
    "      os.system(f\"wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\")\n",
    "      os.system(f\"tar -xzf cifar-10-python.tar.gz --strip-components=1 -C {self.root}\")\n",
    "      \n",
    "    def unpickle(file):\n",
    "      import pickle\n",
    "      with open(file, 'rb') as fo:\n",
    "          dict = pickle.load(fo, encoding='bytes')\n",
    "      return dict\n",
    "    for file_path in ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']:\n",
    "      data_dict = unpickle(f\"{self.root}/{file_path}\")\n",
    "      if self.data is None:\n",
    "        self.data = data_dict[b'data'] # 10000x3072 \n",
    "        self.labels = data_dict[b'labels'] # 10000\n",
    "      else:\n",
    "        self.data = np.concatenate([self.data, data_dict[b'data']], axis=0)\n",
    "        self.labels = np.concatenate([self.labels, data_dict[b'labels']], axis=0)\n",
    "\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    image = self.data[index]\n",
    "    label = self.labels[index]\n",
    "    image = Image.fromarray(image)\n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image)\n",
    "    return image, label\n",
    "\n",
    "def transform(image: Image):\n",
    "  image = np.array(image)\n",
    "  image = image.reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "  image = Image.fromarray(image).resize((224, 224))\n",
    "  image = np.array(image)\n",
    "  \n",
    "  \n",
    "  image = image / 255.0\n",
    "  image = image - np.array([0.485, 0.456, 0.406])\n",
    "  image = image / np.array([0.229, 0.224, 0.225])\n",
    "  \n",
    "  image = image.transpose(2, 0, 1).astype(np.float32)\n",
    "  return image\n",
    "\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"data/cifar10\",\n",
    "    train=(split == \"train\"),\n",
    "    download=False,\n",
    "    transform=transform,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkigVqADNeIN"
   },
   "source": [
    "To train a neural network, we will need to feed data in batches.\n",
    "\n",
    "We create data loaders with the batch size determined previously in setup section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "4axnQCtnks_s"
   },
   "outputs": [],
   "source": [
    "dataflow = {}\n",
    "for split in ['train', 'test']:\n",
    "  dataflow[split] = DataLoader(\n",
    "    dataset[split],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5G1Lf6hOLGT"
   },
   "source": [
    "We can print the data type and shape from the training data loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "ReP2g9pD6ppI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[inputs] dtype: torch.float32, shape: torch.Size([32, 3, 224, 224])\n",
      "[targets] dtype: torch.int64, shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in dataflow[\"train\"]:\n",
    "  print(f\"[inputs] dtype: {inputs.dtype}, shape: {inputs.shape}\")\n",
    "  print(f\"[targets] dtype: {targets.dtype}, shape: {targets.shape}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPAEVnixjwb7"
   },
   "source": [
    "### Model (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFr1Js3-e3rJ"
   },
   "source": [
    "In this tutorial, we will import MobileNet provided by torchvision, and use the pre-trained weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "SNLdS_UQjyBf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# Load pre-trained MobileNetV2\n",
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "model = mobilenet_v2()\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB2X6czdV0px"
   },
   "source": [
    "You should observe that the output dimension of the classifier does not match the number of cleasses in CIFAR-10.\n",
    "\n",
    "Now change the output dimension of the classifer to number of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "Nmo4u51gVzXz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# Change the output dimension of the classifer to number of classes\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, NUM_CLASSES)\n",
    "print(model)\n",
    "\n",
    "# Send the model from cpu to gpu\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEtm9nswWT1z"
   },
   "source": [
    "Now the output dimension of the classifer matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_RcCWoQ8Kp1"
   },
   "source": [
    "As this course focuses on efficiency, we will then inspect its model size and (theoretical) computation cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd4Xu-vMyz39"
   },
   "source": [
    "* The model size can be estimated by the number of trainable parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "4gTfqC0B7Uzi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 2236682\n"
     ]
    }
   ],
   "source": [
    "num_params = 0\n",
    "for param in model.parameters():\n",
    "  if param.requires_grad:\n",
    "    num_params += param.numel()\n",
    "print(\"#Params:\", num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAZoIKIbzLa4"
   },
   "source": [
    "* The computation cost can be estimated by the number of [multiply–accumulate operations (MACs)](https://en.wikipedia.org/wiki/Multiply–accumulate_operation) using [TorchProfile](https://github.com/zhijian-liu/torchprofile), we will further use this profiling tool in the future labs ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "OKVmyWCN7qpp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#MACs: 306186464\n"
     ]
    }
   ],
   "source": [
    "num_macs = profile_macs(model, torch.zeros(1, 3, 224, 224).cuda())\n",
    "print(\"#MACs:\", num_macs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYkqpfejzxwq"
   },
   "source": [
    "This model has 2.2M parameters and requires 306M MACs for inference. We will work together in the next few labs to improve its efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjDsY9_KkIjZ"
   },
   "source": [
    "### Optimization (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRg_5KeKLHPj"
   },
   "source": [
    "As we are working on a classification problem, we will apply [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) as our loss function to optimize the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "id": "-K0DEhGKkKfF"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Apply cross entropy as our loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H8YniYeLIdg"
   },
   "source": [
    "We should decide an optimizer for the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "HXANib83LATH"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Choose an optimizer.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9X8SiWYLJw2"
   },
   "source": [
    "(Optional) We can apply a learning rate scheduler during the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "8mJU5aw8KrVX"
   },
   "outputs": [],
   "source": [
    "# TODO(optional):\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2UFRbRYly50"
   },
   "source": [
    "### Training (25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IpHZJpjR7Wy3"
   },
   "source": [
    "We first define the function that optimizes the model for one batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "79GKx_oVl09b"
   },
   "outputs": [],
   "source": [
    "def train_one_batch(\n",
    "  model: nn.Module,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  inputs: torch.Tensor,\n",
    "  targets: torch.Tensor,\n",
    "  scheduler: LRScheduler\n",
    ") -> None:\n",
    "\n",
    "    # TODO:\n",
    "    # Step 1: Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Step 2: Forward inference\n",
    "    predicts = model(inputs)\n",
    "\n",
    "    # Step 3: Calculate the loss\n",
    "    loss = criterion(predicts, targets) * LEARNING_RATE\n",
    "\n",
    "    # Step 4: Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Step 5: Update optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # (Optional Step 6: scheduler)\n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kePTCanalUE"
   },
   "source": [
    "We then define the training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "4SWx96SGajDR"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataflow: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: Optimizer,\n",
    "    scheduler: LRScheduler\n",
    "):\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataflow, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Call train_one_batch function\n",
    "    train_one_batch(model, criterion, optimizer, inputs, targets, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGaYWFFCbD32"
   },
   "source": [
    "Last, we define the evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "hXVXHqimbOIo"
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataflow: DataLoader\n",
    ") -> float:\n",
    "\n",
    "    model.eval()\n",
    "    num_samples = 0\n",
    "    num_correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataflow, desc=\"eval\", leave=False):\n",
    "            # TODO:\n",
    "            # Step 1: Move the data from CPU to GPU\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            # Step 2: Forward inference\n",
    "            predicts = model(inputs)\n",
    "\n",
    "            # Step 3: Convert logits to class indices (predicted class)\n",
    "            predicts = torch.argmax(predicts, dim=1)\n",
    "\n",
    "            # Update metrics\n",
    "            num_samples += targets.size(0)\n",
    "            num_correct += (predicts == targets).sum()\n",
    "\n",
    "    return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWCOYuj5cNg3"
   },
   "source": [
    "With training and evaluation functions, we can finally start training the model!\n",
    "\n",
    "If the training is done properly, the accuracy should simply reach higher than 0.925:\n",
    "\n",
    "***Please screenshot the output model accuracy, hand in as YourID_acc_1.png***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "czZObK4OcPD-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:31<22:44, 151.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 10.051216125488281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for epoch_num in tqdm(range(1, NUM_EPOCH + 1)):\n",
    "  train(model, dataflow[\"train\"], criterion, optimizer, scheduler)\n",
    "  acc = evaluate(model, dataflow[\"test\"])\n",
    "  print(f\"epoch {epoch_num}:\", acc)\n",
    "\n",
    "print(f\"final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao7C2ZSudE0o"
   },
   "source": [
    "Save the weight of the model as \"model.pt\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.12380027770996"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, dataflow[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "vQrW_B-bcygR"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Save the model weight\n",
    "torch.save(model.state_dict(), \"logs/model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6pbapVjdTG3"
   },
   "source": [
    "You will find \"model.pt\" in the current folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqwrM470RNoO"
   },
   "source": [
    "### Export Model (5%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHpw1pWF6d1c"
   },
   "source": [
    "We can also save the model weight in [ONNX Format](https://pytorch.org/docs/stable/onnx_torchscript.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "yd8oq4-O6kla"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to model.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "# TODO:\n",
    "# Specify the input shape\n",
    "\n",
    "onnx_path = 'model.onnx'\n",
    "\n",
    "# TODO:\n",
    "# Export the model to ONNX format\n",
    "\n",
    "print(f\"Model exported to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLnLCIuv7M46"
   },
   "source": [
    "In onnx format, we can observe the model structure using [Netron](https://netron.app/).\n",
    "\n",
    "***Please download the model structure, hand in as YourID_onnx.png.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QjgTo0GduJx"
   },
   "source": [
    "### Inference (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEH0zddHdzH-"
   },
   "source": [
    "Load the saved model weight:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i28yt-XOdweL"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Step 1: Get the model structure (mobilenet_v2 and the classifier)\n",
    "loaded_model =\n",
    "\n",
    "# Step 2: Load the model weight from \"model.pt\".\n",
    "\n",
    "# Step 3: Send the model from cpu to gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEaZWcuheRFv"
   },
   "source": [
    "Run inference with the loaded model weight and check the accuracy\n",
    "\n",
    "***Please screenshot the output model accuracy, hand in as YourID_acc_2.png***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2dMRsPgGeYe6"
   },
   "outputs": [],
   "source": [
    "acc = evaluate(loaded_model, dataflow[\"test\"])\n",
    "print(f\"accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytdLy6EIfoeT"
   },
   "source": [
    "If the accurracy is the same as the accuracy before saved, you have completed PART 1.\n",
    "\n",
    "Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni0FnXXHcgXa"
   },
   "source": [
    "# **Part 2: LLM with torch.compile**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiOzZkitfkmM"
   },
   "source": [
    "In part 2, we will compare the inference speed of the LLM whether we use torch.compile.\n",
    "\n",
    "```torch.compile``` is a new feature in PyTorch 2.0.\n",
    "\n",
    "The following tutorial will help you get to know the usage.\n",
    "\n",
    "[Introduction to torch.compile](https://pytorch.org/tutorials/intermediate/torch_compile_tutorial.html)\n",
    "\n",
    "We will choose ```Llama-3.2-1B-Instruct``` as our LLM model.\n",
    "\n",
    "Make sure you have access to llama before starting Part 2.\n",
    "\n",
    "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bu-ihO_RiaVM"
   },
   "source": [
    "### Loading LLM (20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3LSb5aoiodV"
   },
   "source": [
    "We will first install huggingface and login with your token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7EhC4kl0_CUf"
   },
   "outputs": [],
   "source": [
    "!pip install -U \"huggingface_hub[cli]\"\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUD-npfwki3T"
   },
   "source": [
    "We choose LLaMa 3.2 1B Instruct as our LLM model and load the pretrained model.\n",
    "\n",
    "Model ID: **\"meta-llama/Llama-3.2-1B-Instruct\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjCkbW_i8VUq"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# TODO:\n",
    "# Load the LLaMA 3.2 1B Instruct model\n",
    "model_id =\n",
    "tokenizer = AutoTokenizer.from_pretrained()\n",
    "model = AutoModelForCausalLM.from_pretrained(, torch_dtype=torch.float16).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1F8VBtODHX2"
   },
   "source": [
    "First we need to decide our prompt to feed into LLM and the maximum token length as well.\n",
    "\n",
    "You can also change the iteration times of testing for the following tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJMPtSLuCzCq"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Input prompt\n",
    "# You can change the prompt whatever you want, e.g. \"How to learn a new language?\", \"What is Edge AI?\"\n",
    "\n",
    "prompt =\n",
    "inputs = tokenizer(, return_tensors=\"pt\").to(\"cuda\")\n",
    "max_token_length =\n",
    "iter_times = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiHloHdRKaaY"
   },
   "source": [
    "### Inference with torch.compile (10%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWj3sD_PJL7Z"
   },
   "source": [
    "Let's define a timer function to compare the speed up of ```torch.compile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oNK4ukXZb631"
   },
   "outputs": [],
   "source": [
    "def timed(fn):\n",
    "  start = torch.cuda.Event(enable_timing=True)\n",
    "  end = torch.cuda.Event(enable_timing=True)\n",
    "  start.record()\n",
    "  result = fn()\n",
    "  end.record()\n",
    "  torch.cuda.synchronize()\n",
    "  return result, start.elapsed_time(end) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4IDTZYbJxJj"
   },
   "source": [
    "After everything is set up, let's start!\n",
    "\n",
    "We first simply run the inference without ```torch.compile```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-u-fBCU-b7hS"
   },
   "outputs": [],
   "source": [
    "original_times = []\n",
    "\n",
    "# Timing without torch.compile\n",
    "for i in range(iter_times):\n",
    "  with torch.no_grad():\n",
    "    original_output, original_time = timed(lambda: model.generate(**inputs, max_length=max_token_length, pad_token_id=tokenizer.eos_token_id))\n",
    "  original_times.append(original_time)\n",
    "  print(f\"Time taken without torch.compile: {original_time} seconds\")\n",
    "\n",
    "# Decode the output\n",
    "output_text = tokenizer.decode(original_output[0], skip_special_tokens=True)\n",
    "print(f\"Output without torch.compile: {output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeVhUlk_K9La"
   },
   "source": [
    "Before using ```torch.compile```, we need to access the model's ```generation_config``` attribute and set the ```cache_implementation``` to \"static\".\n",
    "\n",
    "To use ```torch.compile```, we need to call ```torch.compile``` on the model to compile the forward pass with the static kv-cache.\n",
    "\n",
    "Reference: https://huggingface.co/docs/transformers/llm_optims?static-kv=basic+usage%3A+generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQkTIDusb_7i"
   },
   "outputs": [],
   "source": [
    "compile_times = []\n",
    "\n",
    "# Remind that whenever you use torch.compile, you need to use torch._dynamo.reset() to clear all compilation caches and restores the system to its initial state.\n",
    "import torch._dynamo\n",
    "torch._dynamo.reset()\n",
    "\n",
    "# TODO:\n",
    "# Compile the model\n",
    "model.generation_config.cache_implementation = \"static\"\n",
    "compiled_model =\n",
    "\n",
    "# Timing with torch.compile\n",
    "for i in range(iter_times):\n",
    "  with torch.no_grad():\n",
    "    compile_output, compile_time = timed(lambda: compiled_model.generate(**inputs, max_length=max_token_length, pad_token_id=tokenizer.eos_token_id))\n",
    "  compile_times.append(compile_time)\n",
    "  print(f\"Time taken with torch.compile: {compile_time} seconds\")\n",
    "\n",
    "# Decode output\n",
    "output_text = tokenizer.decode(compile_output[0], skip_special_tokens=True)\n",
    "print(f\"\\nOutput with torch.compile: {output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFZMBADDTo5T"
   },
   "source": [
    "We can easily observe that after the first inference, the inference time drops a lot!\n",
    "\n",
    "Below code can tell you how much faster did ```torch.compile``` did.\n",
    "\n",
    "***Please screenshot the inference time and speedup below, hand in as YourID_speedup.png***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPbqAgo6P7et"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "original_med = np.median(original_times)\n",
    "compile_med = np.median(compile_times)\n",
    "speedup = original_med / compile_med\n",
    "print(f\"Original median: {original_med},\\nCompile median: {compile_med},\\nSpeedup: {speedup}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXdb901VmrZS"
   },
   "source": [
    "You've finished part 2.\n",
    "\n",
    "Congratulations!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
